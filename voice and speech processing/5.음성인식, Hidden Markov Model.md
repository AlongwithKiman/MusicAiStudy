# 음성인식, Hidden Markov Model
## 1. Linear Prediction Coding

음성을 만들어내는 Vocal Tract Model을 잘 활용하면, 음성인식에 사용할 수 있다.  
어떤 phone이 있을 때, 이게 filter의 parameter에 의해 음성으로 변환되는 것이므로, Filter의 parameter을 예측하면 역으로 phone을 알아내는 데 활용할 수 있을 것이다.

- 가정
    - Vocal Tract Model의 n번째 결과물인 음성 s[n]은, 이전 결과물들(s[n-i])의 선형조합으로 표현될 수 있음을 가정.
- 일련의 과정을 통해, filter의 parameter을 얻을 수 있다. ( 정확히 이해는 못함 )
    - Z - transform을 통한 에러에 관한 식 얻기
    - 이런 저런 최적화 방법을 통해서 **필터의 parameter 추정** 가능.


## 2-1. Hidden Markov Model ( 사전 작업 ) 

목표 : 일련의 음성 신호들을 가지고, 이게 어떤 phone들의 sequence인지 추정하기.  
조건 : (당연히) 음성 신호들은 관측 가능한 상태이고, 대신 이게 어떤 phone들이었는지는 모른다.  
구체화 된 목표는 다음과 같다.
> $P(w_1w_2w_3…w_n)$ 가 가장 큰 word sequence 구하기.

- Markov Chain
    ![image](https://user-images.githubusercontent.com/43671432/177914734-5c2cc850-76a5-4b14-9c59-107e66f72272.png) 

    - 위 모델에서 state i → state j 간의 이동 확률은 state i에 의해서만 결정되지, 그 전전의 state들이 뭐였는지는 상관 없다.

- 가정
    - i번째 단어 확률은 바로 직전 i-1번째 단어에만 영향 받음
    - $P(w_i|w_1w_2w_3 … w_{i-1}) \approx P(w_i|w_{i-1})$ 
    - $\therefore        P(w_1w_2…w_n) = \prod_{i=1}^{n}  p(w_i|w_{i-1}) $ ← by 베이즈정리    

## 2-2.Hidden Markov Model Process

### 1) Hidden Markov Chain
   ![image](https://user-images.githubusercontent.com/43671432/177914801-21570a11-b278-4919-8334-dbb0553164a9.png)

- 크게 5개의 구성 성분이 있다.
    - (Hidden) state : ex) 관측할 수 없는 phone
    - Observation  : ex) 실제 관측하는 음성
    - Initial State 확률
    - $a_{ij}$ : state i → j 로 넘어갈 확률, parameter 1
    - $b_j(O_t)$ : state j 에서, $O_t$ 관찰될 확률, parameter 2
- 이거 가지고 Hidden Markov Chain 그릴 수 있고, 모든 좋은 파라미터들을 얻는다면, Observation(음성 sequence)으로부터 최적의 State Path ( $P(w_1w_2w_3…w_n)$ 가 가장 큰 word sequence ) ( = expected phone sequence )  도출할 수 있다.

### 2) Process 1 - 최적의 path 얻기
a. **Likelihood(우도) 계산**
- 모든 Observation들의 likelihood를 계산
    - Using Bayes’ Theory
    - 그냥 계산하려면 계산량이 매우 많다 ( 지수 스케일일듯 )
    - Forward Algorithm 사용
        - Dynamic Programming
    
   > 해당 process의 결과 : **모든 Observation들의 likelihood**
    
    
b. **Decoding : 최적의 hidden state path 구하기**
- 음성인식에서 Hidden Markov Model의 궁극적 목표 :  
    Observation(음성)들만 보고, 이게 어떤 hidden state sequence(phone)의 결과일지 추측하기
- 모델에서 $\hat{y}$ 도출하는 과정
- Vitervi Algorithm 활용
    - 갖고 있는 Observation들 나타내는, 확률 가장 큰 state path 찾아내기

### 2) Process 2 - 모델 학습하기 
- **모든 좋은 파라미터**들을 얻는다면, Observation으로부터 최적의 State Path ( = expected phone ) 도출할 수 있다.
- 파라미터를 학습시켜야 함
- Parameters
    - $a_{ij}$ : i → j 확률
    - $b_j(v_k)$ : j state에서, $v_k$ Observe 확률
- $\hat{a}_{ij}$ = i → j 가는 기댓값 / i → (everywhere) 로 가는 기댓값
    - let   $ξ_t(i,j) = P(q_t = i, q_{t+1} = j | O,\lambda)$
        - t 시점에 i, 그 다음 t+1 시점에 j state 일 확률
    - $\hat{a}_{ij}$ = $\Sigma_{t=1}^{T-1} ξ_t(i,j) / \Sigma_{t=1}^{T-1} \Sigma_{k=1}^{N} ξ_t(i,k)$
- $\hat{b}_j(v_k)$ :  j state 이면서, $O_t$도 $V_k$ 인 경우 / j state 인 경우
    - $\hat{b}_j(v_k)$ = $\Sigma_{t=1 s.t.O_t = v_k}^{T} \gamma_t(j) / \Sigma_{t=1}^T \gamma_t(j)$
- parameter 학습 구현은 Baum-Welch Algorithm 따름
